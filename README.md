# ğŸ­ Multimodal Emotion Recognition (MER) Framework

A high-performance **real-time multimodal emotion recognition system** that combines facial emotion detection and speech emotion recognition using state-of-the-art deep learning models.


## ğŸ—ï¸ **System Architecture**

### **Processing Pipeline**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Video Thread  â”‚    â”‚   Audio Thread  â”‚
â”‚                 â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  OpenCV     â”‚ â”‚    â”‚ â”‚ SoundDevice â”‚ â”‚
â”‚ â”‚ Haar Cascadeâ”‚ â”‚    â”‚ â”‚  Capture    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚        â”‚    â”‚        â”‚        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  DeepFace   â”‚ â”‚    â”‚ â”‚ wav2vec2    â”‚ â”‚
â”‚ â”‚ Emotion CNN â”‚ â”‚    â”‚ â”‚ Transformer â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Fusion Engine   â”‚
        â”‚ - Confidence    â”‚
        â”‚ - Similarity    â”‚ 
        â”‚ - Temporal      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Final Emotion   â”‚
        â”‚   Prediction    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is a simple **multimodal emotion recognition prototype** that combines **facial expressions** (from webcam) and **speech prosody** (from microphone) to predict a userâ€™s emotional state in real time.


## âš™ï¸ Installation

### 1. Clone repository
```bash
git clone https://github.com/jjeff-link/empathy_mer.git
cd empathy_mer
```

### 2. Create Virtual Environment
```bash
python3 -m venv multimodal-env
source multimodal-env/bin/activate   # macOS/Linux
multimodal-env\Scripts\activate      # Windows (PowerShell)
```

### 3. Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Run the prototype:
```bash
python mer.py
```



##  Acknowledgments

### **Models & Frameworks**
- **SuperB Consortium**: `wav2vec2-base-superb-er` emotion recognition model
- **DeepFace**: Meta's facial analysis framework  
- **Hugging Face**: Transformers library and model hosting
- **OpenCV**: Computer vision library

### **Architecture**
- **wav2vec2**: Facebook's self-supervised speech representation learning
- **PyTorch**: Deep learning framework
- **SoundDevice**: Real-time audio processing

